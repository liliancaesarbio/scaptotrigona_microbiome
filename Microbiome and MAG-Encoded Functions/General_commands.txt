#### HERE YOU WILL FIND AND OVERVIEW OF COMMANDS USED. CUSTUM SCRIPTS ARE IN INDIVIDUAL FILES IN THIS SAME FOLDER.
## CDS prediction and annotation from MAGs
for sample in ${sample[*]}; do
	prokka --kingdom Bacteria --outdir ${sample}_prokka --prefix bac /path/${sample}.fa_renamed.fasta_red.fasta
done



## CDS prediction and annotation from all contigs
sample=(SBBP1_FOOD SBBP1_FORAGER SBBP1_GUARD SBBP1_HONEY SBBP1_LARVAE SBBP1_NURSE SBBP1_POLLEN SBBP2_FOOD SBBP2_FORAGER SBBP2_GUARD SBBP2_HONEY SBBP2_LARVAE SBBP2_NURSE SBBP4_POLLEN SDBP2_HONEY SDBP3_FOOD SDBP3_FORAGER SDBP3_GUARD SDBP3_LARVAE SDBP3_NURSE SDBP3_POLLEN SDBP4_FOOD SDBP4_FORAGER SDBP4_GUARD SDBP4_HONEY SDBP4_LARVAE SDBP4_NURSE SDBP4_POLLEN)
for sample in ${sample[*]}; do
	prokka --kingdom Bacteria --outdir ${sample}_prokka --prefix bac /path/contigs1500_${sample}.fasta
done


## RECOVER BACTERIAL CONTIGS
# diamond
for sample in ${sample[*]}; do
        diamond blastp -d /N/soft/blastdb/nr -q /path/${sample}_prokka2/bac.faa --query-cover 90 --subject-cover 90 --top 5 -o ${sample}_diamondP --outfmt 6 --threads 24
done

# recover taxa
for sample in ${sample[*]}; do
        python ann_taxa.py ${sample}_diamondP ${sample}_diamondP_taxa
done

# get taxa per protein in the contig
for sample in ${sample[*]}; do
	python taxa_contig.py /path/bac.gff ${sample}_diamondP_taxa ${sample}_taxa_node
done


# consensus contig taxa
for sample in ${sample[*]}; do
	python classify_node.py ${sample}_taxa_node > ${sample}_taxa_node_consensus
done


# make files with the list of contigs per taxa
for i in *_taxa_node_consensus; do python make_list_contigs_per_taxa.py ${i}; done


# get a list of proteins from each bacterial contig per sample
#!/bin/bash
for sample in ${sample[*]}; do
	grep -F -w -f ${sample}_taxa_node_consensus_bacteria.txt /path/${sample}_prokka2/bac.gff | grep -E '^\b' > ${sample}_lines
	awk -F 'ID=|;' '{print $2}' ${sample}_lines > ${sample}_bacteria_proteins
done


# get the bacteria fastas for each sample
for sample in ${sample[*]}; do
	python /path/get_seqs_from_list.py /path/${sample}_prokka2/bac.faa ${sample}_bacteria_proteins
done





## EGGNOG MAPPER
for sample in ${sample[*]}; do
	emapper.py -i /path/${sample}_bacteria_proteins.fasta -o output_eggnog_${sample} --data_dir /path/eggNOG_data -m diamond --cpu 24
done




# GET COVERAGE PER PROTEIN, based on mappings from "Metagenome Assembly and Binning"
sample=(SBBP1_FOOD SBBP1_FORAGER SBBP1_GUARD SBBP1_HONEY SBBP1_LARVAE SBBP1_NURSE SBBP1_POLLEN SBBP2_FOOD SBBP2_FORAGER SBBP2_GUARD SBBP2_HONEY SBBP2_LARVAE SBBP2_NURSE SBBP4_POLLEN SDBP2_HONEY SDBP3_FOOD SDBP3_FORAGER SDBP3_GUARD SDBP3_LARVAE SDBP3_NURSE SDBP3_POLLEN SDBP4_FOOD SDBP4_FORAGER SDBP4_GUARD SDBP4_HONEY SDBP4_LARVAE SDBP4_NURSE SDBP4_POLLEN)
for sample in ${sample[*]}; do
	awk -F'\t|;|ID=' '{print $1, $10, $4, $5}' /path/${sample}_lines ${sample}_bac_coordinates
done


# get depth files
for sample in ${sample[*]}; do
	cd ${sample}_*spades
	samtools depth -a ${sample}_sorted.bam > ${sample}_depthbins.txt
    samtools idxstats ${sample}_sorted.bam > ${sample}_statsbins.txt
    cd ..
done

# depth files structure
NODE_1_length_277471_cov_26.142735      1       3
NODE_1_length_277471_cov_26.142735      2       3
NODE_1_length_277471_cov_26.142735      3       3
NODE_1_length_277471_cov_26.142735      4       3
NODE_1_length_277471_cov_26.142735      5       3
NODE_1_length_277471_cov_26.142735      6       4

# coord file structure
NODE_12 DNJANLEF_01194 39 689
NODE_12 DNJANLEF_01195 689 1333
NODE_12 DNJANLEF_01196 1430 1615
NODE_12 DNJANLEF_01197 1792 2178

# cov by gene
for sample in ${sample[*]}; do
	python cov_gene.py -verbose /path/${sample}_bac_coordinates /path/${sample}_depthbins.txt > cov_by_gene_${sample}
done


# calculate RPKM of genes
/N/project/NewtonLab/lilian/scaptotrigona_metag_2022/2024/09_coverage_bygene/bins/rpm_genes.sh
for i in cov_by_gene_*; do rpm_genes.sh ${i} ${i}_rpm; done



## classify BRITE
#print columns of interest
for i in *.emapper.annotations; do awk -F'\t' '{print $1, $12}' ${i} > ${i}_ko; done

# delete first lines
for i in *_ko; do awk 'NR > 5 { gsub(/ko:/, ""); print }' ${i} > ${i}ok; done

# print each KO in a line
for i in *kook; do awk -F' ' '{
    if ($2 == "-") {
        print $1, $2;
    } else {
        n = split($2, kos, ",");
        for (i = 1; i <= n; i++) {
            print $1, kos[i];
        }
    }
}' OFS='\t' ${i} > ${i}_byline; done


## get KO classification according BRITE
for sample in ${sample[*]}; do
	python /path/class_BRITE_ko.py ../output_eggnog_${sample}.emapper.annotations_kook_byline output_${sample}_BRITE
done


# organize BTIRE
for i in *BRITE; do python /path/organize_BRITEinfo.py ${i} > ${i}_briteline; done

for sample in ${sample[*]}; do
	python prot_ko_brite.py ../output_eggnog_${sample}.emapper.annotations_kook_byline output_${sample}_BRITE_briteline ${sample}_prot_ko_brite
done

inout1 structure
FBKMMLCL_00020  K03811
FBKMMLCL_00028  -
FBKMMLCL_00032  -

inout2 structure
K03811 09180 Brite Hierarchies
K03811 09183 Protein families: signaling and cellular processes
K03811 02000 Transporters


# remove lines with or starting with, some protein had just 1 dash that where not removed 
for i in *_prot_ko_brite; do grep -Ev "Not Included in Pathway or Brite|Brite Hierarchies|##|[[:space:]]*-[[:space:]]*-" ${i} > ${i}_ok; done

Not Included in Pathway or Brite
Brite Hierarchies
##
- -


#fix input to get cov per prot
for sample in ${sample[*]}; do
awk '{
    if (NF > 2) {
        $1=$1; 
        for(i=3;i<=NF;i++) {
            if (i==3) $3=$3;
            else $3=$3"_"$i;
        }
        NF=3
    }
    print
}' /path/${sample}_prot_ko_brite_ok > ${sample}_prot_ko_brite_ok_underl
done


# RPM per BRITE
input1 SDBP4_POLLEN_prot_ko_brite_ok_underl
FBKMMLCL_00020  K03811 Protein families: signaling and cellular processes
FBKMMLCL_00020  K03811 Transporters
FBKMMLCL_00033  K03530 Chromosome and associated proteins

input2 cov_by_gene_SDBP4_POLLEN_rpm
25.25503        NODE_1  405     851     FBKMMLCL_00020 48.6094
17.42407        NODE_1  864     1403    FBKMMLCL_00033 33.5368
29.26515        NODE_1  1414    1677    FBKMMLCL_00034 56.3279


# first fix inout2
for i in *_rpm; do sed 's/ \+/\t/g' ${i} > ${i}ok; done

# then run script for matching
for sample in ${sample[*]}; do
	python prot_kos_brites_cov.py /path/${sample}_prot_ko_brite_ok_underl /path/cov_by_gene_${sample}_rpmok /path/${sample}_cov_brites
done

# sum covs per brite groups
for i in *cov_brites; do python sum_columns.py ${i} ${i}_sum; done

# get a list of all functions per sample
for i in *sum; do awk '{print $3}' ${i} | sort | uniq > ${i}_list; done

# now use the script update_sumfiles.sh to include in each sum file the missing brite functions, all should end with the same number of functions
for sample in ${sample[*]}; do
	bash update_sumfiles.sh ${sample}_cov_brites_sum all_brites_list_uniq {sample}_allbrites
done

# print filename in the file then cat all
for i in *_allbrites; do awk '{print $0, FILENAME}' ${i} > ${i}ok; done







#### ENRICHMENT ANALYSES, implements the Wilcoxon rank-sum test and evaluates enrichments
# in R
library(dplyr)
library(stats)
library(tidyr)
library(ggplot2)

perform_brite_enrichment <- function(data, coverage_column = "cov_RPM") {
  # First, identify types with multiple samples
  valid_types <- data %>%
    group_by(type) %>%
    summarise(sample_count = n_distinct(sample)) %>%
    filter(sample_count > 1) %>%
    pull(type)
  
  # Filter data to include only valid types
  filtered_data <- data %>%
    filter(type %in% valid_types)
  
  # Initialize results list
  all_results <- list()
  
  # For each type
  for (current_type in valid_types) {
    # Get data for current type
    type_data <- filtered_data %>%
      filter(type == current_type)
    
    # For each BRITE category
    brite_results <- data.frame()
    
    for (brite_cat in unique(type_data$BRITE)) {
      # Compare this type's coverage for this BRITE vs. other types
      brite_in_type <- type_data[[coverage_column]][type_data$BRITE == brite_cat]
      brite_in_others <- filtered_data[[coverage_column]][
        filtered_data$type != current_type & 
          filtered_data$BRITE == brite_cat
      ]
      
      # Perform Wilcoxon test if we have enough data
      if (length(brite_in_type) >= 3 && length(brite_in_others) >= 3) {
        test_result <- wilcox.test(brite_in_type, brite_in_others, 
                                   alternative = "greater")
        
        # Calculate statistics
        fold_change <- mean(brite_in_type) / mean(brite_in_others)
        
        brite_results <- rbind(brite_results, data.frame(
          type = current_type,
          BRITE = brite_cat,
          p_value = test_result$p.value,
          fold_change = fold_change,
          mean_coverage_type = mean(brite_in_type),
          mean_coverage_others = mean(brite_in_others),
          n_samples_type = length(unique(type_data$sample[type_data$BRITE == brite_cat])),
          n_samples_others = length(unique(filtered_data$sample[
            filtered_data$type != current_type & 
              filtered_data$BRITE == brite_cat
          ]))
        ))
      }
    }
    
    # Adjust p-values if we have results
    if (nrow(brite_results) > 0) {
      brite_results$adjusted_p <- p.adjust(brite_results$p_value, method = "BH")
      brite_results <- brite_results %>%
        arrange(adjusted_p, p_value)
      
      all_results[[current_type]] <- brite_results
    }
  }
  
  return(all_results)
}


print_significant_results <- function(results, alpha = 0.05, output_file = NULL) {
  # Create a connection to the output file if specified
  if (!is.null(output_file)) {
    file_conn <- file(output_file, "w")
    sink(file_conn)
  }
  
  # Print header
  cat("BRITE Enrichment Analysis Results\n")
  cat("================================\n\n")
  
  for (type in names(results)) {
    cat("\nSignificant BRITE enrichments for", type, "samples:\n")
    cat("------------------------------------------------\n")
    significant <- results[[type]] %>%
      filter(adjusted_p < alpha) %>%
      arrange(adjusted_p)
    
    if (nrow(significant) > 0) {
      print(significant %>% 
              select(BRITE, adjusted_p, fold_change, 
                     mean_coverage_type, mean_coverage_others))
    } else {
      cat("No significant enrichments found\n")
    }
    cat("\n")
  }
  
  # Close the file connection if it was opened
  if (!is.null(output_file)) {
    sink()
    close(file_conn)
    cat(sprintf("Results have been written to: %s\n", output_file))
  }
}

data <- read.csv("cov_perBRITE_allsamples.csv")
results <- perform_brite_enrichment(data, coverage_column = "cov_RPM")
print_significant_results(results, output_file = "brite_enrichment_results.txt")